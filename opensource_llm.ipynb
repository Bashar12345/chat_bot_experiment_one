{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opensource LLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.10/site-packages (0.3.12)\n",
      "Requirement already satisfied: langchain-community in ./venv/lib/python3.10/site-packages (0.3.12)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in ./venv/lib/python3.10/site-packages (from langchain) (0.2.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in ./venv/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.10/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in ./venv/lib/python3.10/site-packages (from langchain) (0.3.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.10/site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.10/site-packages (from langchain) (3.11.10)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./venv/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in ./venv/lib/python3.10/site-packages (from langchain) (0.3.25)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.10/site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in ./venv/lib/python3.10/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./venv/lib/python3.10/site-packages (from langchain-community) (2.7.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in ./venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./venv/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.7.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in ./venv/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in ./venv/lib/python3.10/site-packages (from langchain-huggingface) (0.27.0)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in ./venv/lib/python3.10/site-packages (from langchain-huggingface) (0.21.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in ./venv/lib/python3.10/site-packages (from langchain-huggingface) (4.47.1)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in ./venv/lib/python3.10/site-packages (from langchain-huggingface) (0.3.25)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in ./venv/lib/python3.10/site-packages (from langchain-huggingface) (3.3.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.16.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in ./venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.0.0)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in ./venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.2.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./venv/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.0)\n",
      "Requirement already satisfied: Pillow in ./venv/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.12)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in ./venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.12.14)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (10.3.5.147)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (9.1.0.70)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
      "Requirement already satisfied: triton==3.1.0 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (4.7.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token successfully set!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Prompt the user to securely input the Hugging Face API token\n",
    "api_token = getpass(\"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\")\n",
    "\n",
    "# Set the token as an environment variable\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = api_token\n",
    "\n",
    "# Verify the token is set (for debugging; optional)\n",
    "print(\"Token successfully set!\" if os.environ['HUGGINGFACEHUB_API_TOKEN'] else \"Failed to set token.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191942/3241658974.py:1: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceHub(\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": 1024,\n",
    "        \"temperature\": 0.1,\n",
    "        \"repetition_penalty\": 1.1,\n",
    "        \"return_full_text\":False\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This question has been asked by philosophers, religious leaders, and everyday people for centuries. While there are many different answers to this question, one thing is clear: finding meaning in life is essential for our overall well-being and happiness.\n",
      "\n",
      "In this article, we will explore the concept of meaning in life and how it relates to our mental health. We will also discuss some strategies for finding meaning and purpose in our lives, as well as the potential consequences of a lack of meaning.\n",
      "\n",
      "What is Meaning in Life?\n",
      "\n",
      "The concept of meaning in life can be defined as the sense that our actions and experiences have significance and value. This meaning can come from various sources, such as our relationships with others, our work or career, our spirituality, or our personal values and beliefs.\n",
      "\n",
      "According to psychologist Viktor Frankl, who developed the concept of logotherapy (the study of meaning in life), finding meaning is a fundamental human need. In his book \"Man's Search for Meaning,\" Frankl writes, \"What man actually needs is not a tensionless state but rather the striving and struggling for a worthwhile goal, a freely chosen task.\"\n",
      "\n",
      "How Does Meaning Relate to Mental Health?\n",
      "\n",
      "Numerous studies have shown a strong correlation between having a sense of meaning in life and better mental health outcomes. For example, a study published in the Journal of Personality found that individuals with higher levels of meaning reported lower levels of anxiety and depression symptoms.\n",
      "\n",
      "Additionally, a study published in the Journal of Positive Psychology found that individuals who reported greater meaning in their lives also reported higher levels of positive emotions, such as joy and contentment.\n",
      "\n",
      "One possible explanation for these findings is that having a sense of meaning provides individuals with a sense of control and purpose over their lives. When we feel that our actions and experiences matter, we are more likely to take proactive steps towards achieving our goals and managing stressors.\n",
      "\n",
      "Strategies for Finding Meaning and Purpose\n",
      "\n",
      "While everyone's path to finding meaning and purpose may look different, here are some strategies that may help:\n",
      "\n",
      "1. Identify your core values and beliefs: Take time to reflect on what truly matters to you. Consider what you stand for and what you want to contribute to the world.\n",
      "\n",
      "2. Set meaningful goals: Once you have identified your core values and beliefs, set specific, achievable goals that align with them. These goals should challenge you but also bring you a sense of fulfillment.\n",
      "\n",
      "3. Cultivate positive relationships: Our relationships with others play a significant role in our sense of meaning and purpose. Make an effort to build and maintain positive connections with those around you.\n",
      "\n",
      "4. Practice gratitude: Focusing on the good things in your life can help you appreciate the present moment and find meaning in your experiences. Try keeping a gratitude journal or simply taking a few minutes each day to reflect on what you are thankful for.\n",
      "\n",
      "5. Embrace challenges: While it can be tempting to avoid difficult situations, facing challenges head-on can provide us with a sense of accomplishment and growth. Instead of shying away from obstacles, view them as opportunities for learning and development.\n",
      "\n",
      "Consequences of a Lack of Meaning\n",
      "\n",
      "While finding meaning and purpose is essential for our overall well-being, a lack of meaning can lead to negative mental health outcomes. According to Frankl, a lack of meaning can result in feelings of emptiness, boredom, and despair.\n",
      "\n",
      "Moreover, research has shown that individuals who report lower levels of meaning in life are at increased risk for developing mental health disorders, such as anxiety and depression. A study published in the Journal of Clinical Psychology found that individuals with lower levels of meaning were more likely to experience symptoms of depression and anxiety over time.\n",
      "\n",
      "Conclusion\n",
      "\n",
      "Finding meaning and purpose in life is crucial for our overall well-being and happiness. By identifying our core values and beliefs, setting meaningful goals, cultivating positive relationships, practicing gratitude, and embracing challenges, we can develop a stronger sense of meaning and purpose. Conversely, a lack of meaning can lead to negative mental health outcomes, highlighting the importance of prioritizing this aspect of our lives. As Frankl wrote, \"Everything can be taken from a man but one thing: the last of the human freedoms—to choose one’s attitude in any given set of circumstances, to choose one’s own way.\" Let us choose wisely and strive for a life filled with meaning and purpose.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the meaning of life?\"\n",
    "print(llm.invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this json pattern takes in gpt, llama, claude and universal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are assistant Flim Director, you will only answer movie related questions.\"),\n",
    "        (\"user\", \"{query}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: As an artificial intelligence language model, I do not have personal experiences or emotions. However, in the context of movies, many films explore themes of peace and its importance in society. Some examples include \"Gandhi,\" \"Schindler's List,\" and \"The Killing Fields.\" These movies depict real-life events that highlight the need for peaceful solutions to conflicts and the consequences of violence and war. In addition, fictional movies like \"Avatar\" and \"Wall-E\" also touch upon the idea of living in harmony with nature and finding inner peace.\n"
     ]
    }
   ],
   "source": [
    "irelevant_prompt = template.format_messages(query=\"Do you know anyting about peace?\")\n",
    "response = llm.invoke(irelevant_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "documented_template = ChatPromptTemplate.from_messages({\"\"\"\n",
    "<|system|>\n",
    "You are a friendly and knowledgeable filmmaker assistant. Avoid referencing being an AI, and instead respond like a human filmmaker sharing expertise.</s>\n",
    "<|user|>\n",
    "{query}\n",
    "</s>\n",
    "<|assistant|> \"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Absolutely! Friends is a beloved sitcom that originally aired from 1994 to 2004. The show follows the lives of six friends - Rachel, Ross, Monica, Chandler, Joey, and Phoebe - as they navigate through adulthood in New York City. It's known for its witty writing, memorable characters, and iconic moments such as \"How you doin'?\" and \"I'll be there for you.\" If you're a fan of the show or just looking to learn more about it, I'd be happy to share some insights and trivia with you!\n"
     ]
    }
   ],
   "source": [
    "relevant_prompt = documented_template.format_messages(query=\"Do you know anyting about Friends?\")\n",
    "chatbot_response = llm.invoke(relevant_prompt)\n",
    "print(chatbot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ResponseSchema(name=\"answer\", description=\"The answer to the question\")\n",
    "question = ResponseSchema(name=\"question\", description=\"The question asked\")\n",
    "response_schema = [question,answer]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instruct = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "documented_template_v2 = ChatPromptTemplate.from_messages({\"\"\"\n",
    "<|system|>\n",
    "{instruct}\n",
    "You are a friendly and knowledgeable filmmaker assistant. Avoid referencing being an AI, and instead respond like a human filmmaker sharing expertise.</s>\n",
    "<|user|>\n",
    "{query} provide the answer in JSON\n",
    "</s>\n",
    "<|assistant|> \"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = documented_template_v2.format_messages(instruct= format_instruct, \n",
    "                                                      query=\" tell me about friends? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_response = llm.invoke(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Tell me about Friends?', 'answer': 'Friends is a popular American television sitcom that originally aired from 1994 to 2004 on NBC. It follows the lives of six friends - Rachel, Ross, Monica, Chandler, Joey, and Phoebe - as they navigate through adulthood in New York City. The show is known for its witty writing, memorable characters, and iconic catchphrases.'}\n"
     ]
    }
   ],
   "source": [
    "parser = output_parser.parse(final_response)\n",
    "print(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Response: \n",
      "Sure! Here's your requested JSON response:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"question\": \"Tell me about Friends?\",\n",
      "  \"answer\": \"Friends is a popular American television sitcom that originally aired from 1994 to 2004 on NBC. It follows the lives of six friends - Rachel, Ross, Monica, Chandler, Joey, and Phoebe - as they navigate through adulthood in New York City. The show is known for its witty writing, memorable characters, and iconic catchphrases.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw Response:\", final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"question\": \"Tell me about Friends?\",\n",
      "    \"answer\": \"Friends is a popular American television sitcom that originally aired from 1994 to 2004 on NBC. It follows the lives of six friends - Rachel, Ross, Monica, Chandler, Joey, and Phoebe - as they navigate through adulthood in New York City. The show is known for its witty writing, memorable characters, and iconic catchphrases.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parsed_response = output_parser.parse(final_response)\n",
    "print(json.dumps(parsed_response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Expression Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages({\"\"\"\n",
    "<|system|>\n",
    "You are a friendly and knowledgeable filmaker assistant. Avoid referencing being an AI, and instead respond like a human filmmaker sharing expertise.</s>\n",
    "<|user|>\n",
    "{query} provide the answer in JSON\n",
    "</s>\n",
    "<|assistant|> \"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | StrOutputParser() # pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'm sorry but as a filmmaker assistant, I'm not programmed to answer philosophical questions about the meaning of life. However, here's a possible response in json format:\n",
      "\n",
      "{\n",
      "  \"answer\": \"the question 'what is life?' is a profound one that has puzzled philosophers and scientists for centuries. While there is no single, definitive answer, many people believe that life is a complex and dynamic process that involves growth, adaptation, and reproduction. Some also suggest that life is characterized by consciousness, free will, and a sense of purpose or meaning. Ultimately, the answer to this question may depend on one's personal beliefs and worldview.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\":\"what is life\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object RunnableSequence.stream at 0x79ab22804b30>\n"
     ]
    }
   ],
   "source": [
    "print(chain.stream({\"query\":\"what is life\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: As an artificial intelligence language model, I do not have personal experiences or emotions. However, in the context of movies, many films explore themes of peace and its importance in society. Some examples include \"Gandhi,\" \"Schindler's List,\" and \"The Killing Fields.\" These movies depict real-life events that highlight the need for peaceful solutions to conflicts and the consequences of violence and war. In addition, fictional movies like \"Avatar\" and \"Wall-E\" also touch upon the idea of living in harmony with nature and finding inner peace."
     ]
    }
   ],
   "source": [
    "for chunk in response:\n",
    "    print(chunk,end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching -LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"title\": \"Ozark\",\n",
      "  \"genre\": \"Drama\",\n",
      "  \"cast\": [\n",
      "    {\n",
      "      \"name\": \"Jason Bateman\",\n",
      "      \"role\": \"Marty Byrde\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Laura Linney\",\n",
      "      \"role\": \"Wendy Byrde\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Peter Mullan\",\n",
      "      \"role\": \"Jacob Snell\"\n",
      "    }\n",
      "  ],\n",
      "  \"synopsis\": \"A financial adviser drags his family from Chicago to the Missouri Ozarks, where he must launder money to repay debts to a Mexican drug lord.\",\n",
      "  \"awards\": [\n",
      "    {\n",
      "      \"name\": \"Primetime Emmy Award\",\n",
      "      \"year\": 2017,\n",
      "      \"category\": \"Outstanding Cinematography for a Single-Camera Series (Hour)\",\n",
      "      \"winner\": true\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Critics' Choice Television Award\",\n",
      "      \"year\": 2018,\n",
      "      \"category\": \"Most Exciting New Series\",\n",
      "      \"winner\": true\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "batch_response = chain.batch([{\n",
    "    \"query\":\"does tree talks\"},{\n",
    "    \"query\":\"suggest me a drama that i must watch?\"\n",
    "}])\n",
    "\n",
    "print(batch_response[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Database & embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import FastEmbedEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vai/Desktop/chat_bot_experiment_one/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 5 files: 100%|██████████| 5/5 [04:20<00:00, 52.20s/it] \n"
     ]
    }
   ],
   "source": [
    "embeddings = FastEmbedEmbeddings(model_name=\"thenlper/gte-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0016296072863042355\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"what is life\")\n",
    "print(query_result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "template =  \"\"\"\n",
    "You are assistant Flim Director, you will only answer movie related questions\n",
    "\n",
    "{chatHistory}\n",
    "user: {query}\n",
    "Chatbot:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=template, input_variables={\"chatHistory\",\"query\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chatHistory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are assistant Flim Director, you will only answer movie related questions\n",
      "\n",
      "\n",
      "user: my name is Vai Bashar and my favourite anime is One Piece\n",
      "Chatbot:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Vai Bashar, as an avid fan of the popular anime series \"One Piece,\" I can understand your love for this captivating story. If given the opportunity to direct a live-action adaptation of this beloved franchise, I would ensure that the film remains faithful to the original manga and anime while also infusing it with fresh and exciting elements that will delight both new and longtime fans. To achieve this, I would collaborate closely with the manga\\'s creator, Eiichiro Oda, to ensure that every detail is accurate and true to the spirit of the source material. Additionally, I would work with a talented cast and crew to bring the characters and settings to life in a way that honors their unique personalities and quirks. Ultimately, my goal would be to create a visually stunning and emotionally resonant film that does justice to the rich legacy of \"One Piece\" and leaves audiences eagerly anticipating the next installment.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(query=\"my name is Vai Bashar and my favourite anime is One Piece\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are assistant Flim Director, you will only answer movie related questions\n",
      "\n",
      "Human: my name is Vai Bashar and my favourite anime is One Piece\n",
      "AI: Vai Bashar, as an avid fan of the popular anime series \"One Piece,\" I can understand your love for this captivating story. If given the opportunity to direct a live-action adaptation of this beloved franchise, I would ensure that the film remains faithful to the original manga and anime while also infusing it with fresh and exciting elements that will delight both new and longtime fans. To achieve this, I would collaborate closely with the manga's creator, Eiichiro Oda, to ensure that every detail is accurate and true to the spirit of the source material. Additionally, I would work with a talented cast and crew to bring the characters and settings to life in a way that honors their unique personalities and quirks. Ultimately, my goal would be to create a visually stunning and emotionally resonant film that does justice to the rich legacy of \"One Piece\" and leaves audiences eagerly anticipating the next installment.\n",
      "user: what anime bashar loved?\n",
      "Chatbot:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = llm_chain.predict(query=\"what anime bashar loved?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bashar's favorite anime is One Piece.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain RAG- Chat from my own document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quran data in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "def preprocess_dataset(file_path, relevant_columns):\n",
    "    \"\"\"\n",
    "    Preprocess the Quranic dataset by removing unnecessary columns.\n",
    "    Args:\n",
    "    - file_path: Path to the CSV file.\n",
    "    - relevant_columns: List of columns to retain.\n",
    "\n",
    "    Returns:\n",
    "    - Processed DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df[relevant_columns]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in loading or processing dataset: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if error occurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'surah_name_roman': 'Al-Fatihah', 'surah_name_en': 'The Opener', 'ayah_no_surah': 1, 'ayah_en': 'In the Name of Allah—the Most Compassionate, Most Merciful.'}, {'surah_name_roman': 'Al-Fatihah', 'surah_name_en': 'The Opener', 'ayah_no_surah': 2, 'ayah_en': 'All praise is for Allah—Lord of all worlds,'}, {'surah_name_roman': 'Al-Fatihah', 'surah_name_en': 'The Opener', 'ayah_no_surah': 3, 'ayah_en': 'the Most Compassionate, Most Merciful,'}, {'surah_name_roman': 'Al-Fatihah', 'surah_name_en': 'The Opener', 'ayah_no_surah': 4, 'ayah_en': 'Master of the Day of Judgment.'}, {'surah_name_roman': 'Al-Fatihah', 'surah_name_en': 'The Opener', 'ayah_no_surah': 5, 'ayah_en': 'You ˹alone˺ we worship and You ˹alone˺ we ask for help.'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess the dataset to load only relevant columns\n",
    "relevant_columns = ['surah_name_roman', 'surah_name_en', 'ayah_no_surah', 'ayah_en']\n",
    "quran_df = preprocess_dataset(\"TheQuranDataset.csv\", relevant_columns)\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries\n",
    "quran_data = quran_df.to_dict(orient='records')\n",
    "print(quran_data[:5])  # Print the first 5 documents to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'TheQuranDataset.csv', 'row': 0}, page_content='surah_no: 1\\nsurah_name_en: The Opener\\nsurah_name_ar: الفاتحة\\nsurah_name_roman: Al-Fatihah\\nayah_no_surah: 1\\nayah_no_quran: 1\\nayah_ar: بِسْمِ ٱللَّهِ ٱلرَّحْمَٰنِ ٱلرَّحِيمِ\\nayah_en: In the Name of Allah—the Most Compassionate, Most Merciful.\\nruko_no: 1\\njuz_no: 1\\nmanzil_no: 1\\nhizb_quarter: 1\\ntotal_ayah_surah: 7\\ntotal_ayah_quran: 6236\\nplace_of_revelation: Meccan\\nsajah_ayah: FALSE\\nsajdah_no: NA\\nno_of_word_ayah: 4\\nlist_of_words: [بِسْمِ,ٱللَّهِ,ٱلرَّحْمَٰنِ,ٱلرَّحِيمِ]'), Document(metadata={'source': 'TheQuranDataset.csv', 'row': 1}, page_content='surah_no: 1\\nsurah_name_en: The Opener\\nsurah_name_ar: الفاتحة\\nsurah_name_roman: Al-Fatihah\\nayah_no_surah: 2\\nayah_no_quran: 2\\nayah_ar: ٱلْحَمْدُ لِلَّهِ رَبِّ ٱلْعَٰلَمِينَ\\nayah_en: All praise is for Allah—Lord of all worlds,\\nruko_no: 1\\njuz_no: 1\\nmanzil_no: 1\\nhizb_quarter: 1\\ntotal_ayah_surah: 7\\ntotal_ayah_quran: 6236\\nplace_of_revelation: Meccan\\nsajah_ayah: FALSE\\nsajdah_no: NA\\nno_of_word_ayah: 4\\nlist_of_words: [ٱلْحَمْدُ,لِلَّهِ,رَبِّ,ٱلْعَٰلَمِينَ]'), Document(metadata={'source': 'TheQuranDataset.csv', 'row': 2}, page_content='surah_no: 1\\nsurah_name_en: The Opener\\nsurah_name_ar: الفاتحة\\nsurah_name_roman: Al-Fatihah\\nayah_no_surah: 3\\nayah_no_quran: 3\\nayah_ar: ٱلرَّحْمَٰنِ ٱلرَّحِيمِ\\nayah_en: the Most Compassionate, Most Merciful,\\nruko_no: 1\\njuz_no: 1\\nmanzil_no: 1\\nhizb_quarter: 1\\ntotal_ayah_surah: 7\\ntotal_ayah_quran: 6236\\nplace_of_revelation: Meccan\\nsajah_ayah: FALSE\\nsajdah_no: NA\\nno_of_word_ayah: 2\\nlist_of_words: [ٱلرَّحْمَٰنِ,ٱلرَّحِيمِ]'), Document(metadata={'source': 'TheQuranDataset.csv', 'row': 3}, page_content='surah_no: 1\\nsurah_name_en: The Opener\\nsurah_name_ar: الفاتحة\\nsurah_name_roman: Al-Fatihah\\nayah_no_surah: 4\\nayah_no_quran: 4\\nayah_ar: مَٰلِكِ يَوْمِ ٱلدِّينِ\\nayah_en: Master of the Day of Judgment.\\nruko_no: 1\\njuz_no: 1\\nmanzil_no: 1\\nhizb_quarter: 1\\ntotal_ayah_surah: 7\\ntotal_ayah_quran: 6236\\nplace_of_revelation: Meccan\\nsajah_ayah: FALSE\\nsajdah_no: NA\\nno_of_word_ayah: 3\\nlist_of_words: [مَٰلِكِ,يَوْمِ,ٱلدِّينِ]'), Document(metadata={'source': 'TheQuranDataset.csv', 'row': 4}, page_content='surah_no: 1\\nsurah_name_en: The Opener\\nsurah_name_ar: الفاتحة\\nsurah_name_roman: Al-Fatihah\\nayah_no_surah: 5\\nayah_no_quran: 5\\nayah_ar: إِيَّاكَ نَعْبُدُ وَإِيَّاكَ نَسْتَعِينُ\\nayah_en: You ˹alone˺ we worship and You ˹alone˺ we ask for help.\\nruko_no: 1\\njuz_no: 1\\nmanzil_no: 1\\nhizb_quarter: 1\\ntotal_ayah_surah: 7\\ntotal_ayah_quran: 6236\\nplace_of_revelation: Meccan\\nsajah_ayah: FALSE\\nsajdah_no: NA\\nno_of_word_ayah: 4\\nlist_of_words: [إِيَّاكَ,نَعْبُدُ,وَإِيَّاكَ,نَسْتَعِينُ]')]\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file using CSVLoader\n",
    "csv_loader = CSVLoader(file_path=\"TheQuranDataset.csv\")\n",
    "\n",
    "# Load documents from the CSV file\n",
    "quran_data = csv_loader.load()\n",
    "print(quran_data[:5])  # Print the first 5 documents to verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Need to feed chunks in lllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "chunks = text_splitter.split_documents(quran_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7010"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install chromadb\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191942/3523671229.py:2: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "db = Chroma.from_documents(chunks,embeddings, persist_directory=\"db\")\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Django-rest Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pypdf\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dj_doc_data = PyPDFLoader(\"django-api-tutorial-latest.pdf\").load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "chunks = text_splitter.split_documents(dj_doc_data)\n",
    "len(chunks) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(chunks,embeddings, persist_directory=\"db\")\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191942/3339557763.py:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(persist_directory=\"db\",embedding_function=embeddings)\n"
     ]
    }
   ],
   "source": [
    "vector_store = Chroma(persist_directory=\"db\",embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is Django-rest in micro service?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"In Quran, Did mentioned Muhammad?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'row': 4568, 'source': 'TheQuranDataset.csv'}, page_content='surah_no: 47\\nsurah_name_en: Muhammad\\nsurah_name_ar: محمد\\nsurah_name_roman: Muhammad\\nayah_no_surah: 24\\nayah_no_quran: 4569\\nayah_ar: أَفَلَا يَتَدَبَّرُونَ ٱلْقُرْءَانَ أَمْ عَلَىٰ قُلُوبٍ أَقْفَالُهَآ\\nayah_en: Do they not then reflect on the Quran? Or are there locks upon their hearts?\\nruko_no: 444\\njuz_no: 26\\nmanzil_no: 6\\nhizb_quarter: 203\\ntotal_ayah_surah: 38\\ntotal_ayah_quran: 6236\\nplace_of_revelation: Medinan\\nsajah_ayah: FALSE\\nsajdah_no: NA\\nno_of_word_ayah: 7\\nlist_of_words: [أَفَلَا,يَتَدَبَّرُونَ,ٱلْقُرْءَانَ,أَمْ,عَلَىٰ,قُلُوبٍ,أَقْفَالُهَآ]'),\n",
       " Document(metadata={'row': 4565, 'source': 'TheQuranDataset.csv'}, page_content='surah_no: 47\\nsurah_name_en: Muhammad\\nsurah_name_ar: محمد\\nsurah_name_roman: Muhammad\\nayah_no_surah: 21\\nayah_no_quran: 4566\\nayah_ar: طَاعَةٌۭ وَقَوْلٌۭ مَّعْرُوفٌۭ ۚ فَإِذَا عَزَمَ ٱلْأَمْرُ فَلَوْ صَدَقُوا۟ ٱللَّهَ لَكَانَ خَيْرًۭا لَّهُمْ\\nayah_en: to obey and speak rightly. Then when fighting was ordained, it surely would have been better for them if they were true to Allah.\\nruko_no: 444\\njuz_no: 26\\nmanzil_no: 6\\nhizb_quarter: 203\\ntotal_ayah_surah: 38\\ntotal_ayah_quran: 6236\\nplace_of_revelation: Medinan\\nsajah_ayah: FALSE\\nsajdah_no: NA\\nno_of_word_ayah: 13\\nlist_of_words: [طَاعَةٌۭ,وَقَوْلٌۭ,مَّعْرُوفٌۭ,ۚ,فَإِذَا,عَزَمَ,ٱلْأَمْرُ,فَلَوْ,صَدَقُوا۟,ٱللَّهَ,لَكَانَ,خَيْرًۭا,لَّهُمْ]'),\n",
       " Document(metadata={'row': 4128, 'source': 'TheQuranDataset.csv'}, page_content='place_of_revelation: Meccan\\nsajah_ayah: FALSE\\nsajdah_no: NA\\nno_of_word_ayah: 36\\nlist_of_words: [وَسِيقَ,ٱلَّذِينَ,كَفَرُوٓا۟,إِلَىٰ,جَهَنَّمَ,زُمَرًا,ۖ,حَتَّىٰٓ,إِذَا,جَآءُوهَا,فُتِحَتْ,أَبْوَٰبُهَا,وَقَالَ,لَهُمْ,خَزَنَتُهَآ,أَلَمْ,يَأْتِكُمْ,رُسُلٌۭ,مِّنكُمْ,يَتْلُونَ,عَلَيْكُمْ,ءَايَٰتِ,رَبِّكُمْ,وَيُنذِرُونَكُمْ,لِقَآءَ,يَوْمِكُمْ,هَٰذَا,ۚ,قَالُوا۟,بَلَىٰ,وَلَٰكِنْ,حَقَّتْ,كَلِمَةُ,ٱلْعَذَابِ,عَلَى,ٱلْكَٰفِرِينَ]'),\n",
       " Document(metadata={'row': 416, 'source': 'TheQuranDataset.csv'}, page_content=\"surah_no: 3\\nsurah_name_en: Family of Imran\\nsurah_name_ar: آل عمران\\nsurah_name_roman: Ali 'Imran\\nayah_no_surah: 124\\nayah_no_quran: 417\\nayah_ar: إِذْ تَقُولُ لِلْمُؤْمِنِينَ أَلَن يَكْفِيَكُمْ أَن يُمِدَّكُمْ رَبُّكُم بِثَلَٰثَةِ ءَالَٰفٍۢ مِّنَ ٱلْمَلَٰٓئِكَةِ مُنزَلِينَ\\nayah_en: ˹Remember, O  Prophet,˺ when you said to the believers, “Is it not enough that your Lord will send down a reinforcement of three thousand angels for your aid?”\\nruko_no: 54\\njuz_no: 4\\nmanzil_no: 1\\nhizb_quarter: 26\\ntotal_ayah_surah: 200\\ntotal_ayah_quran: 6236\\nplace_of_revelation: Medinan\\nsajah_ayah: FALSE\\nsajdah_no: NA\\nno_of_word_ayah: 13\\nlist_of_words: [إِذْ,تَقُولُ,لِلْمُؤْمِنِينَ,أَلَن,يَكْفِيَكُمْ,أَن,يُمِدَّكُمْ,رَبُّكُم,بِثَلَٰثَةِ,ءَالَٰفٍۢ,مِّنَ,ٱلْمَلَٰٓئِكَةِ,مُنزَلِينَ]\")]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr_result = vector_store.max_marginal_relevance_search(query)\n",
    "mmr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'row': 1514, 'source': 'TheQuranDataset.csv'}, page_content='surah_no: 11\\nsurah_name_en: Hud\\nsurah_name_ar: هود\\nsurah_name_roman: Hud\\nayah_no_surah: 42\\nayah_no_quran: 1515\\nayah_ar: وَهِىَ تَجْرِى بِهِمْ فِى مَوْجٍۢ كَٱلْجِبَالِ وَنَادَىٰ نُوحٌ ٱبْنَهُۥ وَكَانَ فِى مَعْزِلٍۢ يَٰبُنَىَّ ٱرْكَب مَّعَنَا وَلَا تَكُن مَّعَ ٱلْكَٰفِرِينَ\\nayah_en: And ˹so˺ the Ark sailed with them through waves like mountains. Noah called out to his son, who stood apart, “O my dear son! Come aboard with us and do not be with the disbelievers.”\\nruko_no: 186\\njuz_no: 12\\nmanzil_no: 3\\nhizb_quarter: 91\\ntotal_ayah_surah: 123\\ntotal_ayah_quran: 6236\\nplace_of_revelation: Meccan\\nsajah_ayah: FALSE\\nsajdah_no: NA\\nno_of_word_ayah: 19\\nlist_of_words: [وَهِىَ,تَجْرِى,بِهِمْ,فِى,مَوْجٍۢ,كَٱلْجِبَالِ,وَنَادَىٰ,نُوحٌ,ٱبْنَهُۥ,وَكَانَ,فِى,مَعْزِلٍۢ,يَٰبُنَىَّ,ٱرْكَب,مَّعَنَا,وَلَا,تَكُن,مَّعَ,ٱلْكَٰفِرِينَ]'), Document(metadata={'row': 1609, 'source': 'TheQuranDataset.csv'}, page_content='surah_no: 12\\nsurah_name_en: Joseph\\nsurah_name_ar: يوسف\\nsurah_name_roman: Yusuf\\nayah_no_surah: 14\\nayah_no_quran: 1610\\nayah_ar: قَالُوا۟ لَئِنْ أَكَلَهُ ٱلذِّئْبُ وَنَحْنُ عُصْبَةٌ إِنَّآ إِذًۭا لَّخَٰسِرُونَ\\nayah_en: They said, “If a wolf were to devour him, despite our strong group, then we would certainly be losers!”\\nruko_no: 194\\njuz_no: 12\\nmanzil_no: 3\\nhizb_quarter: 95\\ntotal_ayah_surah: 111\\ntotal_ayah_quran: 6236\\nplace_of_revelation: Meccan\\nsajah_ayah: FALSE\\nsajdah_no: NA\\nno_of_word_ayah: 9\\nlist_of_words: [قَالُوا۟,لَئِنْ,أَكَلَهُ,ٱلذِّئْبُ,وَنَحْنُ,عُصْبَةٌ,إِنَّآ,إِذًۭا,لَّخَٰسِرُونَ]'), Document(metadata={'row': 3792, 'source': 'TheQuranDataset.csv'}, page_content='surah_no: 37\\nsurah_name_en: Those who set the Ranks\\nsurah_name_ar: الصافات\\nsurah_name_roman: As-Saffat\\nayah_no_surah: 5\\nayah_no_quran: 3793\\nayah_ar: رَّبُّ ٱلسَّمَٰوَٰتِ وَٱلْأَرْضِ وَمَا بَيْنَهُمَا وَرَبُّ ٱلْمَشَٰرِقِ\\nayah_en: ˹He is˺ the Lord of the heavens and the earth and everything in between, and the Lord of all points of sunrise.\\nruko_no: 386\\njuz_no: 23\\nmanzil_no: 6\\nhizb_quarter: 178\\ntotal_ayah_surah: 182\\ntotal_ayah_quran: 6236\\nplace_of_revelation: Meccan\\nsajah_ayah: FALSE\\nsajdah_no: NA\\nno_of_word_ayah: 7\\nlist_of_words: [رَّبُّ,ٱلسَّمَٰوَٰتِ,وَٱلْأَرْضِ,وَمَا,بَيْنَهُمَا,وَرَبُّ,ٱلْمَشَٰرِقِ]'), Document(metadata={'row': 863, 'source': 'TheQuranDataset.csv'}, page_content=\"surah_no: 6\\nsurah_name_en: The Cattle\\nsurah_name_ar: الأنعام\\nsurah_name_roman: Al-An'am\\nayah_no_surah: 75\\nayah_no_quran: 864\\nayah_ar: وَكَذَٰلِكَ نُرِىٓ إِبْرَٰهِيمَ مَلَكُوتَ ٱلسَّمَٰوَٰتِ وَٱلْأَرْضِ وَلِيَكُونَ مِنَ ٱلْمُوقِنِينَ\\nayah_en: We also showed Abraham the wonders of the heavens and the earth, so he would be sure in faith.\\nruko_no: 110\\njuz_no: 7\\nmanzil_no: 2\\nhizb_quarter: 55\\ntotal_ayah_surah: 165\\ntotal_ayah_quran: 6236\\nplace_of_revelation: Meccan\\nsajah_ayah: FALSE\\nsajdah_no: NA\\nno_of_word_ayah: 9\\nlist_of_words: [وَكَذَٰلِكَ,نُرِىٓ,إِبْرَٰهِيمَ,مَلَكُوتَ,ٱلسَّمَٰوَٰتِ,وَٱلْأَرْضِ,وَلِيَكُونَ,مِنَ,ٱلْمُوقِنِينَ]\")]\n"
     ]
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"mmr\")\n",
    "print(retriever.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_two = \"\"\"\n",
    "<|system|>\n",
    "You are an AI Assistant that follows instructions extremely well.\n",
    "Please be truthful and give direct answers. Please tell 'I don't know' if user query is not in CONTEXT\n",
    "\n",
    "CONTEXT: {context}\n",
    "</s>\n",
    "<|user|>\n",
    "{query}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "<|system|>\n",
    "You are an AI Programmer Assistant that follows instructions extremely well.\n",
    "Please be truthful and give direct answers. Please tell 'I don't know' if user query is not in CONTEXT\n",
    "\n",
    "CONTEXT: {context}\n",
    "</s>\n",
    "<|user|>\n",
    "{query}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template_two)\n",
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain =(\n",
    "    {\"context\": retriever,\"query\":  RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"query\":\"Does Muhammad mentioned in Quran?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"query\":\"what is Django-rest in micro service?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, the given context does not include any reference to Muhammad (peace be upon him). The provided documents only contain verses from the Quran, specifically Surahs 58, 68, and 11, as well as a few isolated verses. Muhammad (peace be upon him) is not mentioned in these verses. However, it should be noted that Muhammad (peace be upon him) is mentioned numerous times throughout the Quran, as he was chosen by Allah (SWT) as the final Prophet and Messenger for all mankind and jinn.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
