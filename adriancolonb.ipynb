{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytesseract\n",
    "%pip install pdf2image\n",
    "%pip install fitz pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Date 28.04.2019 Physician Dr. M. Jaksch Freiburg Medical Lab Laboratory Report Online Version Remarks Note Our reference values are adjusted to age and gender. Daily internal Quality Control within the required range according to ISO 15189. External Quality Control available on request. nonaccredited parameter This parameter is affected by Biotin intake of 5 mg RDI 0.03mg This investigation has been performed in a collaborating accredited laboratory Germany. Page 1 of 3 Patient Name Diabetes Profile sample report Gender Female Date of Birth 01.01.1973 Nationality Your ID Test Request Code 1278 Sample ID Patient IDNo 380032 Sampling Date Time27.04.2019 1709 Receipt Date Time 27.04.2019 1709 This report has been printed through ImedOnlineReportingSystem and therefore does not carry a signature. Insurance Freiburg Medical Laboratory Middle East L.L.C. P.O. Box 3068, Dubai UAE, Tel 04 396 2227, Fax 04 396 2228 Email infofmldubai.com, Website www.fmldubai.com Techn. Validation by Dr. Nehmat ElBanna PD Dr. med. habil. M. Jaksch Med. Technologist Specialist Associate Professor Supervisor of Clinical Pathology US Medical Director the Department DHAP0084548 DHALS240710 Analysis Result Flag Units Reference Range ProteinsMetabolites Serum Glucose Recommendation of the American Diabetes Association Glucose fasting PHO 83 mgdl 70 99 Please note that we have adjusted our reference ranges according to the recommendations of the American Diabetes Association Glucose Level 70 99 Normal fasting glucose 100 125 Impaired fasting glucose prediabetes 126 Suspicion of diabetes Please note that glucose in full blood without stabilizers such as NaF is only stable for 10 minutes. Please send us NaF blood. ProteinsMetabolites Serum Lipid Studies in mgdl Recommendations for Adults from the American Heart Association Cholesterol, total PHO 221 high mgdl 100 200 Normal 100 199, Desirable 200, Borderline 200 239, High Risk 240 Triglycerides PHO 1315 high mgdl 150 Normal 150, Borderline 150 199, High 200 499, Very High 500 HDL Cholesterol, direct PHO 22.5 low mgdl 50 Increased Risk Men 40, Increased Risk Women 50, Normal 50 60, Optimal 60 LDL Cholesterol, direct PHO 36 mgdl 100 Optimal 100, Near Optimal 100 129, Borderline 130 159, High 160 189 Very High 190 Report Date 28.04.2019 Physician Dr. M. Jaksch Freiburg Medical Lab Laboratory Report Online Version Remarks Note Our reference values are adjusted to age and gender. Daily internal Quality Control within the required range according to ISO 15189. External Quality Control available on request. nonaccredited parameter This parameter is affected by Biotin intake of 5 mg RDI 0.03mg This investigation has been performed in a collaborating accredited laboratory Germany. Page 2 of 3 Patient Name Diabetes Profile sample report Gender Female Date of Birth 01.01.1973 Nationality Your ID Test Request Code 1278 Sample ID Patient IDNo 380032 Sampling Date Time27.04.2019 1709 Receipt Date Time 27.04.2019 1709 This report has been printed through ImedOnlineReportingSystem and therefore does not carry a signature. Insurance Freiburg Medical Laboratory Middle East L.L.C. P.O. Box 3068, Dubai UAE, Tel 04 396 2227, Fax 04 396 2228 Email infofmldubai.com, Website www.fmldubai.com Techn. Validation by Dr. Nehmat ElBanna PD Dr. med. habil. M. Jaksch Med. Technologist Specialist Associate Professor Supervisor of Clinical Pathology US Medical Director the Department DHAP0084548 DHALS240710 Analysis Result Flag Units Reference Range ProteinsMetabolites Serum Lipid Studies in mmoll Recommendations for Adults from the American Heart Association Cholesterol, total PHO 5.7 high mmoll 2.6 5.1 Normal 2.6 5.1, Desirable 5.2, Borderline 5.2 6.2, High Risk 6.2 Triglycerides PHO 14.8 high mmoll 1.7 Normal 1.7, Borderline 1.7 2.2, High 2.2 5.6, Very High 5.6 HDL Cholesterol, direct PHO 0.6 low mmoll 1.3 Increased Risk Men 1.0, Increased Risk Women 1.3, Normal 1.3 1.6, Optimal 1.6 LDL Cholesterol, direct PHO 0.9 mmoll 2.6 Optimal 2.6, Near Optimal 2.6 3.3, Borderline 3.4 4.1, High 4.2 4.9, Very High 4.9 ProteinsMetabolites Serum Albumin PHO 4.5 gdl 3.5 5.0 Urea Nitrogen PHO 9 mgdl 6 20 Creatinine PHO 0.7 mgdl 0.4 0.9 Creatinine is related to the muscle mass. Please note that we have slightly adjusted the reference ranges based on own evaluations in the AsianArabic population. Total Protein PHO 7.1 gdl 6.4 8.3 ProteinsMetabolites EDTA blood Hb A1c TURB 3.8 2.9 4.2 Report Date 28.04.2019 Physician Dr. M. Jaksch Freiburg Medical Lab Laboratory Report Online Version Remarks Note Our reference values are adjusted to age and gender. Daily internal Quality Control within the required range according to ISO 15189. External Quality Control available on request. nonaccredited parameter This parameter is affected by Biotin intake of 5 mg RDI 0.03mg This investigation has been performed in a collaborating accredited laboratory Germany. Page 3 of 3 Patient Name Diabetes Profile sample report Gender Female Date of Birth 01.01.1973 Nationality Your ID Test Request Code 1278 Sample ID Patient IDNo 380032 Sampling Date Time27.04.2019 1709 Receipt Date Time 27.04.2019 1709 This report has been printed through ImedOnlineReportingSystem and therefore does not carry a signature. Insurance Freiburg Medical Laboratory Middle East L.L.C. P.O. Box 3068, Dubai UAE, Tel 04 396 2227, Fax 04 396 2228 Email infofmldubai.com, Website www.fmldubai.com Techn. Validation by Dr. Nehmat ElBanna PD Dr. med. habil. M. Jaksch Med. Technologist Specialist Associate Professor Supervisor of Clinical Pathology US Medical Director the Department DHAP0084548 DHALS240710 Analysis Result Flag Units Reference Range 4.36.5 good control 6.67.5 satisfactory control 7.5 unsatisfactory control Our HbA1c method is performed according to the IFCC standard. Please note, that the IFCC Standards are more sensitive and are able to recognize a pathologic Glucose tolerance at the earliest. No sign of diabetic glucose metabolism glycosylation. Decreased HbA1c levels are observed in hemolytic anemia.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pytesseract\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from typing import Dict, List\n",
    "\n",
    "class MedicalScanPipeline:\n",
    "    \"\"\"\n",
    "    A high-performance, scalable pipeline for processing uploaded medical scan reports.\n",
    "    It extracts textual data, formats the content, generates context, and predicts key medical insights.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, disease_model: str =None, abnormality_model: str=None):\n",
    "        self.ocr_processor = pytesseract.image_to_string\n",
    "        # self.disease_pipeline = self._load_model_pipeline(disease_model)\n",
    "        # self.abnormality_pipeline = self._load_model_pipeline(abnormality_model)\n",
    "    \n",
    "\n",
    "    \n",
    "    def process_scan(self, file_path: str) -> Dict:\n",
    "        \"\"\"Processes a scanned medical document (PDF or image) and returns structured medical insights.\"\"\"\n",
    "        extracted_text = self._extract_text(file_path)\n",
    "        formatted_text = self._format_text(extracted_text)\n",
    "        context = self._generate_context(formatted_text)\n",
    "        key_insights = self._extract_key_insights(context)\n",
    "        return key_insights\n",
    "    \n",
    "    def _extract_text(self, file_path: str) -> str:\n",
    "        \"\"\"Extracts raw text from an uploaded scanned medical document (PDF or image).\"\"\"\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File {file_path} not found.\")\n",
    "        \n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(\".pdf\"):\n",
    "            text = self._extract_text_from_pdf(file_path)\n",
    "        else:\n",
    "            text = self.ocr_processor(Image.open(file_path))\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def _extract_text_from_pdf(self, file_path: str) -> str:\n",
    "        \"\"\"Extracts text from a PDF using PyMuPDF, with a fallback to OCR if necessary.\"\"\"\n",
    "        extracted_text = \"\"\n",
    "        with fitz.open(file_path) as doc:\n",
    "            for page in doc:\n",
    "                extracted_text += page.get_text(\"text\") + \"\\n\"\n",
    "        \n",
    "        if not extracted_text.strip():  # If no text is found, use OCR\n",
    "            images = convert_from_path(file_path)\n",
    "            extracted_text = \"\\n\".join([self.ocr_processor(img) for img in images])\n",
    "        \n",
    "        return extracted_text.strip()\n",
    "    \n",
    "    def _format_text(self, text: str) -> str:\n",
    "        \"\"\"Cleans and formats extracted text for further processing.\"\"\"\n",
    "        text = re.sub(r'[^\\w\\s.,]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def _generate_context(self, text: str) -> str:\n",
    "        \"\"\"Generates structured context from formatted medical text.\"\"\"\n",
    "        return f\"Medical Report Analysis:\\n{text}\\nEnd of Report.\"\n",
    "    \n",
    "    def _extract_key_insights(self, context: str) -> Dict:\n",
    "        \"\"\"Extracts key insights including lab results, predicted diseases, and abnormalities.\"\"\"\n",
    "        lab_key_points = self._extract_lab_key_points(context)\n",
    "        predicted_disease = self._predict_disease(context)\n",
    "        abnormality_analysis = self._analyze_abnormalities(context)\n",
    "        \n",
    "        return {\n",
    "            \"lab_key_points\": lab_key_points,\n",
    "            \"predicted_disease\": predicted_disease,\n",
    "            \"abnormalities\": abnormality_analysis\n",
    "        }\n",
    "    \n",
    "    def _extract_key_insights(self, context: str) -> Dict:\n",
    "        \"\"\"Extracts key insights including lab results, predicted diseases, and abnormalities.\"\"\"\n",
    "        lab_key_points = self._extract_lab_key_points(context)\n",
    "        predicted_disease = self._predict_disease(context)\n",
    "        abnormality_analysis = self._analyze_abnormalities(context)\n",
    "        \n",
    "        return {\n",
    "            \"lab_key_points\": lab_key_points,\n",
    "            \"predicted_disease\": predicted_disease,\n",
    "            \"abnormalities\": abnormality_analysis\n",
    "        }\n",
    "    \n",
    "    def _extract_lab_key_points(self, context: str) -> List[str]:\n",
    "        \"\"\"Extracts key points from the medical lab report using AI.\"\"\"\n",
    "        return self._medical_ai(context, task=\"extract_lab_values\")\n",
    "    \n",
    "    def _predict_disease(self, context: str) -> str:\n",
    "        \"\"\"Predicts potential diseases based on the provided medical context using AI.\"\"\"\n",
    "        return self._medical_ai(context, task=\"predict_disease\")\n",
    "    \n",
    "    def _analyze_abnormalities(self, context: str) -> str:\n",
    "        \"\"\"Analyzes the medical text for any abnormal indicators of sickness using AI.\"\"\"\n",
    "        return self._medical_ai(context, task=\"detect_abnormalities\")\n",
    "\n",
    "    \n",
    "    def _medical_ai(self, text: str, task: str) -> str:\n",
    "        \"\"\"An obfuscated AI-based method to process medical context and return insights.\"\"\"\n",
    "        import os\n",
    "        import requests\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        \n",
    "        endpoint = os.getenv(\"MEDICAL_AI_ENDPOINT\")\n",
    "        Model = os.getenv(\"MEDICAL_AI_MODEL\")\n",
    "        oak = os.getenv(\"MEDICAL_AI_OAK\")\n",
    "        \n",
    "        print(f\"Endpoint: {endpoint}, Model: {Model}, OAK: {oak}\")\n",
    "        \n",
    "        headers = {\"Authorization\": f\"Bearer {oak}\", \"Content-Type\": \"application/json\"}\n",
    "        payload = {\"input\": text, \"task\": task, \"model\": Model}\n",
    "        \n",
    "        response = requests.post(endpoint, json=payload, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json().get(\"output\", \"No relevant insights found.\")\n",
    "        return \"AI processing unavailable\"\n",
    "\n",
    "\n",
    "# Usage Example:\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = MedicalScanPipeline()\n",
    "    # report = pipeline.process_scan(\"docs/sample_medical_report_2.pdf\")\n",
    "    # print(pipeline._extract_text_from_pdf(\"docs/sample_medical_report_2.pdf\"))\n",
    "    print(pipeline._format_text(pipeline._extract_text_from_pdf(\"docs/sample_medical_report_2.pdf\")))\n",
    "    # print(report._extract_text_from_pdf())\n",
    "    # print(json.dumps(report, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static method called\n",
      "Class method called, class variable: Shared\n"
     ]
    }
   ],
   "source": [
    "class Example:\n",
    "    class_variable = \"Shared\"\n",
    "\n",
    "    @staticmethod\n",
    "    def static_method():\n",
    "        return \"Static method called\"\n",
    "\n",
    "    @classmethod\n",
    "    def class_method(cls):\n",
    "        return f\"Class method called, class variable: {cls.class_variable}\"\n",
    "\n",
    "print(Example.static_method())   # ✅ Works fine\n",
    "print(Example.class_method())    # ✅ Accesses class-level attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"lab_key_points\": \"**Phase 1 - LAB ANALYSIS:**\\n\\nKey laboratory values extracted and formatted with reference ranges:\\n\\n- Glucose Fasting: 83 mg/dl (Reference Range: 70-99 mg/dl)\\n- Total Cholesterol: 221 mg/dl (Reference Range: 100-200 mg/dl) High\\n- Triglycerides: 1315 mg/dl (Reference Range: <150 mg/dl) High\\n- HDL cholesterol: 22.5 mg/dl (Reference Range: >50 mg/dl) Low\\n- LDL cholesterol: 36 mg/dl (Reference Range: 100 mg/dl) Optimal\\n- Total Cholesterol: 5.7 mmol/l (Reference Range: 2.6-5.1 mmol/l) High\\n- Triglycerides: 14.8 mmol/l (Reference Range: <1.7 mmol/l) High\\n- HDL cholesterol: 0.6 mmol/l (Reference Range: >1.3 mmol/l) Low\\n- LDL cholesterol: 0.9 mmol/l (Reference Range: 2.6 mmol/l) Optimal\\n- Albumin: 4.5 g/dl (Reference Range: 3.5\\u20135.0 g/dl)\\n- Urea Nitrogen: 9 mg/dl (Reference Range: 6-20 mg/dl)\\n- Creatinine: 0.7 mg/dl (Reference Range: 0.4-0.9 mg/dl)\\n- Total Protein: 7.1 g/dl (Reference Range: 6.4\\u20138.3 g/dl)\\n- Hb A1c (Glycated hemoglobin): 3.8 (Reference Range: 4.3\\u20136.5 good control)\\n\\n**Phase 2 - DISEASE PREDICTION:**\\n\\nPotential diagnoses based on above lab values:\\n\\n- Hyperlipidemia: Suggested by high total cholesterol and triglycerides, low HDL cholesterol\\n- No evidence of Diabetes: Fasting glucose and Hb A1c levels are within normal range\\n\\n**Phase 3 - ABNORMALITY DETECTION:**\\n\\nSignificant deviations and explanation:\\n\\n- High total cholesterol (Both mg/dl and mmol/l measurements): This indicates that the patient has high levels of cholesterol in their blood.\\n- High triglycerides (Both mg/dl and mmol/l measurements): This is an indication of an abundance of lipids in the blood.\\n- Low HDL cholesterol (Both mg/dl and mmol/l measurements): A low HDL level may increase the risk of heart disease.\\n- The lab values for creatinine, urea nitrogen, and albumin are within the normal range, indicating normal kidney and liver function. \\n- The normal Hb A1c level suggests good diabetes control or non-diabetic state.\",\n",
      "    \"predicted_disease\": \"1. LAB ANALYSIS: \\n\\n- Glucose, Serum: 83 mg/dl (Reference: 70\\u201399 mg/dl)\\n- Total Cholesterol, Serum: 221 mg/dl (Reference: 100\\u2013200 mg/dl)\\n- Triglycerides, Serum: 1315 mg/dl (Reference: below 150 mg/dl)\\n- HDL Cholesterol, direct, Serum: 22.5 mg/dl (Reference: above 50 mg/dl)\\n- LDL Cholesterol, direct, Serum: 36 mg/dl (Reference: below 100 mg/dl)\\n- Albumin, Serum: 4.5 g/dl (Reference: 3.5\\u20135 g/dl)\\n- Urea Nitrogen, Serum: 9 mg/dl (Reference: 6\\u201320 mg/dl)\\n- Creatinine, Serum: 0.7 mg/dl (Reference: 0.4\\u20130.9 mg/dl)\\n- Total Protein, Serum: 7.1 g/dl (Reference: 6.4\\u20138.3 g/dl)\\n- Hb A1c, EDTA blood: 3.8 (Reference: 2.9\\u20134.2)\\n\\n2. DISEASE PREDICTION:\\n- Hypertriglyceridemia: Due to elevated Triglycerides 1315 mg/dl (normal <150 mg/dl).\\n- Low HDL Syndrome: The patient's HDL level 22.5 mg/dl is below the desired level of more than 50 mg/dl.\\n- Hypercholesterolemia: Suggested by elevated Total Cholesterol 221 mg/dl (normal 100\\u2013200 mg/dl).\\n\\n3. ABNORMALITY DETECTION:\\n- Significantly High Triglycerides: 1315 mg/dl, which is much higher than the normal range. High levels may increase the risk of pancreatitis.\\n- Low HDL Cholesterol: 22.5 mg/dl, which is below the reference range. This could indicate risk for heart disease as HDL is considered \\\"good\\\" cholesterol.\\n- High Total Cholesterol: 221 mg/dl, above the normal range 100-200 mg/dl, indicating hypercholesterolemia. This may pose risk for atherosclerosis and heart disease.\",\n",
      "    \"abnormalities\": \"**Phase 1: LAB ANALYSIS**\\n\\n- Glucose (Fasting): 83 mg/dl (Reference Range: 70 - 99 mg/dl)\\n- Total Cholesterol: 221 mg/dl (Reference Range: 100 - 200 mg/dl)\\n- Triglycerides: 1315 mg/dl (Reference Range: Below 150 mg/dl)\\n- HDL Cholesterol: 22.5 mg/dl (Reference Range: Above 50 mg/dl)\\n- LDL Cholesterol: 36 mg/dl (Reference Range: Below 130 mg/dl)\\n- Serum Albumin: 4.5 g/dl (Reference Range: 3.5 - 5.0 g/dl)\\n- Urea Nitrogen: 9 mg/dl (Reference Range: 6 - 20 mg/dl)\\n- Creatinine: 0.7 mg/dl (Reference Range: 0.4 - 0.9 mg/dl)\\n- Total Protein: 7.1 g/dl (Reference Range: 6.4 - 8.3 g/dl)\\n- Hb A1c: 3.8 (Reference Range: Below 5.7 if non diabetic)\\n\\n**Phase 2: DISEASE PREDICTION**\\n\\n- Based on the above results, the patient may potentially have hyperlipidemia, as indicated by the high levels of Total Cholesterol and Triglycerides, and low level of HDL cholesterol. \\n- No indication of diabetes as the fasting glucose and HbA1c levels are within the normal range.\\n\\n**Phase 3: ABNORMALITY DETECTION**\\n\\n- Total Cholesterol: Elevated (221 mg/dl, Normal: 100 - 200 mg/dl), indicating high risk for cardiovascular diseases.\\n- Triglycerides: Highly Elevated (1315 mg/dl, Normal: <150 mg/dl), indicating very high risk for pancreatitis.\\n- HDL Cholesterol: Low (22.5 mg/dl, Normal: >50 mg/dl), indicates increased risk for heart disease.\\n- Remaining lab parameters are within the normal reference range.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import re ,requests\n",
    "import json\n",
    "import pytesseract\n",
    "import fitz  # PyMuPDF\n",
    "# import torch\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "# from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from typing import Dict, List\n",
    "import importlib.util\n",
    "\n",
    "class MedicalScanPipeline:\n",
    "    \"\"\"\n",
    "    A high-performance, scalable pipeline for processing uploaded medical scan reports.\n",
    "    It extracts textual data, formats the content, generates context, and predicts key medical insights.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, disease_model: str = \"bert-base-uncased\", abnormality_model: str = \"distilbert-base-uncased\"):\n",
    "        self.ocr_processor = pytesseract.image_to_string\n",
    "        # self.disease_pipeline = self._load_model_pipeline(disease_model)\n",
    "        # self.abnormality_pipeline = self._load_model_pipeline(abnormality_model)\n",
    "        self.ai_client = self._initialize_ai_client()\n",
    "    \n",
    "    # @staticmethod\n",
    "    # def _load_model_pipeline(model_name: str):\n",
    "    #     \"\"\"Loads a transformer model for classification tasks.\"\"\"\n",
    "    #     tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    #     model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    #     return pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "    \n",
    "    def _initialize_ai_client(self):\n",
    "        \"\"\"Dynamically loads the AI client to obscure OpenAI dependency.\"\"\"\n",
    "        spec = importlib.util.find_spec(\"openai\")\n",
    "        if spec is None:\n",
    "            return None\n",
    "        ai_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(ai_module)\n",
    "        return ai_module.ChatCompletion\n",
    "    \n",
    "    def process_scan(self, file_path: str) -> Dict:\n",
    "        \"\"\"Processes a scanned medical document (PDF or image) and returns structured medical insights.\"\"\"\n",
    "        extracted_text = self._extract_text(file_path)\n",
    "        formatted_text = self._format_text(extracted_text)\n",
    "        context = self._generate_context(formatted_text)\n",
    "        key_insights = self._extract_key_insights(context)\n",
    "        return key_insights\n",
    "    \n",
    "    def _extract_text(self, file_path: str) -> str:\n",
    "        \"\"\"Extracts raw text from an uploaded scanned medical document (PDF or image).\"\"\"\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File {file_path} not found.\")\n",
    "        \n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(\".pdf\"):\n",
    "            text = self._extract_text_from_pdf(file_path)\n",
    "        else:\n",
    "            text = self.ocr_processor(Image.open(file_path))\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def _extract_text_from_pdf(self, file_path: str) -> str:\n",
    "        \"\"\"Extracts text from a PDF using PyMuPDF, with a fallback to OCR if necessary.\"\"\"\n",
    "        extracted_text = \"\"\n",
    "        with fitz.open(file_path) as doc:\n",
    "            for page in doc:\n",
    "                extracted_text += page.get_text(\"text\") + \"\\n\"\n",
    "        \n",
    "        if not extracted_text.strip():  # If no text is found, use OCR\n",
    "            images = convert_from_path(file_path)\n",
    "            extracted_text = \"\\n\".join([self.ocr_processor(img) for img in images])\n",
    "        \n",
    "        return extracted_text.strip()\n",
    "    \n",
    "    def _format_text(self, text: str) -> str:\n",
    "        \"\"\"Cleans and formats extracted text for further processing.\"\"\"\n",
    "        text = re.sub(r'[^\\w\\s.,]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def _generate_context(self, text: str) -> str:\n",
    "        \"\"\"Generates structured context from formatted medical text.\"\"\"\n",
    "        return f\"Medical Report Analysis:\\n{text}\\nEnd of Report.\"\n",
    "    \n",
    "    def _extract_key_insights(self, context: str) -> Dict:\n",
    "        \"\"\"Extracts key insights including lab results, predicted diseases, and abnormalities.\"\"\"\n",
    "        lab_key_points = self._extract_lab_key_points(context)\n",
    "        predicted_disease = self._predict_disease(context)\n",
    "        abnormality_analysis = self._analyze_abnormalities(context)\n",
    "        \n",
    "        return {\n",
    "            \"lab_key_points\": lab_key_points,\n",
    "            \"predicted_disease\": predicted_disease,\n",
    "            \"abnormalities\": abnormality_analysis\n",
    "        }\n",
    "    \n",
    "    def _extract_lab_key_points(self, context: str) -> List[str]:\n",
    "        \"\"\"Extracts key points from the medical lab report using AI.\"\"\"\n",
    "        return self._medical_ai(context, task=\"extract_lab_values\")\n",
    "    \n",
    "    def _predict_disease(self, context: str) -> str:\n",
    "        \"\"\"Predicts potential diseases based on the provided medical context using AI.\"\"\"\n",
    "        return self._medical_ai(context, task=\"predict_disease\")\n",
    "    \n",
    "    def _analyze_abnormalities(self, context: str) -> str:\n",
    "        \"\"\"Analyzes the medical text for any abnormal indicators of sickness using AI.\"\"\"\n",
    "        return self._medical_ai(context, task=\"detect_abnormalities\")\n",
    "    \n",
    "    def _medical_ai(self, text: str, task: str) -> str:\n",
    "        \"\"\"Handles AI-based medical analysis using a secure external API execution.\"\"\"\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        \n",
    "        hitspoint = os.getenv(\"MEDICAL_AIPOINT\")\n",
    "        \n",
    "        # Debug: Print raw environment values\n",
    "        def safe_json_load(json_str: str) -> dict:\n",
    "            try:\n",
    "                # Handle Windows-style line continuations\n",
    "                cleaned = json_str.replace('\\\\\\n', '').replace('\\\\n', '\\n')\n",
    "                return json.loads(cleaned)\n",
    "            except (json.JSONDecodeError, AttributeError) as e:\n",
    "                print(f\"JSON Error: {str(e)}\")\n",
    "                print(f\"Problematic JSON: {json_str}\")\n",
    "                return {}\n",
    "\n",
    "        hd = safe_json_load(os.getenv(\"MEDICAL_AI_HEAD\").replace(\"'\", '\"'))\n",
    "        data = safe_json_load(os.getenv(\"AI_BODY\").replace(\"'\", '\"'))\n",
    "\n",
    "        # Replace placeholders\n",
    "        if \"messages\" in data and len(data[\"messages\"]) > 1:\n",
    "            data[\"messages\"][1][\"content\"] = f\"Task: {task} , Text: {text}\"\n",
    "            \n",
    "        \n",
    "        response = requests.post(hitspoint, json=data, headers=hd)\n",
    "        return response.json().get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"AI processing unavailable\")\n",
    "\n",
    "# Usage Example:\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = MedicalScanPipeline()\n",
    "    report = pipeline.process_scan(\"docs/sample_medical_report_2.pdf\")\n",
    "    print(json.dumps(report, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LabReportAgent:\n",
    "    \"\"\"Agent for extracting key points from medical lab reports using AI.\"\"\"\n",
    "    @staticmethod\n",
    "    def extract(context: str) -> List[str]:\n",
    "        return MedicalAI.request(context, task=\"extract_lab_values\")\n",
    "\n",
    "class DiseasePredictionAgent:\n",
    "    \"\"\"Agent for predicting diseases from medical context using AI.\"\"\"\n",
    "    @staticmethod\n",
    "    def predict(context: str) -> str:\n",
    "        return MedicalAI.request(context, task=\"predict_disease\")\n",
    "\n",
    "class AbnormalityDetectionAgent:\n",
    "    \"\"\"Agent for detecting abnormalities in medical text using AI.\"\"\"\n",
    "    @staticmethod\n",
    "    def analyze(context: str) -> str:\n",
    "        return MedicalAI.request(context, task=\"detect_abnormalities\")\n",
    "\n",
    "class MedicalAI:\n",
    "    \"\"\"Hidden AI-based service for processing medical insights using GPT-4.\"\"\"\n",
    "    @staticmethod\n",
    "    def request(text: str, task: str) -> str:\n",
    "        import os\n",
    "        import requests\n",
    "        \n",
    "        endpoint = os.getenv(\"MEDICAL_AI_ENDPOINT\")\n",
    "        api_key = os.getenv(\"MEDICAL_AI_KEY\")\n",
    "        \n",
    "        headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "        payload = {\"input\": text, \"task\": task, \"model\": \"gpt-4-medical\"}\n",
    "        \n",
    "        response = requests.post(endpoint, json=payload, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json().get(\"output\", \"No relevant insights found.\")\n",
    "        return \"AI processing unavailable\"\n",
    "\n",
    "# Usage Example:\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = MedicalScanPipeline()\n",
    "    pipeline.lab_agent = LabReportAgent()\n",
    "    pipeline.disease_agent = DiseasePredictionAgent()\n",
    "    pipeline.abnormality_agent = AbnormalityDetectionAgent()\n",
    "    \n",
    "    report = pipeline.process_scan(\"sample_medical_report.pdf\")\n",
    "    print(json.dumps(report, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 124\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Usage Example:\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 124\u001b[0m     pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mMedicalScanPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     report \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mprocess_scan(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_medical_report.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(report, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m, in \u001b[0;36mMedicalScanPipeline.__init__\u001b[0;34m(self, disease_model, abnormality_model)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mocr_processor \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_string\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisease_pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model_pipeline(disease_model)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mabnormality_pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabnormality_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_ai_client()\n",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m, in \u001b[0;36mMedicalScanPipeline._load_model_pipeline\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads a transformer model for classification tasks.\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m---> 29\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n",
      "File \u001b[0;32m~/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/transformers/modeling_utils.py:3825\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3809\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m   3811\u001b[0m     cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3812\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[1;32m   3813\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3823\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m: commit_hash,\n\u001b[1;32m   3824\u001b[0m     }\n\u001b[0;32m-> 3825\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3827\u001b[0m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[1;32m   3828\u001b[0m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[1;32m   3829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[1;32m   3830\u001b[0m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    418\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m~/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/huggingface_hub/file_download.py:860\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    842\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    858\u001b[0m     )\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1009\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1007\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1009\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1020\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1543\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1541\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1543\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1552\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1553\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m~/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/huggingface_hub/file_download.py:452\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    450\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 452\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[1;32m    454\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/urllib3/response.py:1066\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1066\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1069\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/urllib3/response.py:955\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 955\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    876\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pytesseract\n",
    "import fitz  # PyMuPDF\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from typing import Dict, List\n",
    "import importlib.util\n",
    "\n",
    "class MedicalScanPipeline:\n",
    "    \"\"\"\n",
    "    A high-performance, scalable pipeline for processing uploaded medical scan reports.\n",
    "    It extracts textual data, formats the content, generates context, and predicts key medical insights.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, disease_model: str = \"bert-base-uncased\", abnormality_model: str = \"distilbert-base-uncased\"):\n",
    "        self.ocr_processor = pytesseract.image_to_string\n",
    "        self.disease_pipeline = self._load_model_pipeline(disease_model)\n",
    "        self.abnormality_pipeline = self._load_model_pipeline(abnormality_model)\n",
    "        self.ai_client = self._initialize_ai_client()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_model_pipeline(model_name: str):\n",
    "        \"\"\"Loads a transformer model for classification tasks.\"\"\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        return pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "    \n",
    "    def _initialize_ai_client(self):\n",
    "        \"\"\"Dynamically loads the AI client to obscure OpenAI dependency.\"\"\"\n",
    "        spec = importlib.util.find_spec(\"openai\")\n",
    "        if spec is None:\n",
    "            return None\n",
    "        ai_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(ai_module)\n",
    "        return ai_module.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    def process_scan(self, file_path: str) -> Dict:\n",
    "        \"\"\"Processes a scanned medical document (PDF or image) and returns structured medical insights.\"\"\"\n",
    "        extracted_text = self._extract_text(file_path)\n",
    "        formatted_text = self._format_text(extracted_text)\n",
    "        context = self._generate_context(formatted_text)\n",
    "        key_insights = self._extract_key_insights(context)\n",
    "        return key_insights\n",
    "    \n",
    "    def _extract_text(self, file_path: str) -> str:\n",
    "        \"\"\"Extracts raw text from an uploaded scanned medical document (PDF or image).\"\"\"\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File {file_path} not found.\")\n",
    "        \n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(\".pdf\"):\n",
    "            text = self._extract_text_from_pdf(file_path)\n",
    "        else:\n",
    "            text = self.ocr_processor(Image.open(file_path))\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def _extract_text_from_pdf(self, file_path: str) -> str:\n",
    "        \"\"\"Extracts text from a PDF using PyMuPDF, with a fallback to OCR if necessary.\"\"\"\n",
    "        extracted_text = \"\"\n",
    "        with fitz.open(file_path) as doc:\n",
    "            for page in doc:\n",
    "                extracted_text += page.get_text(\"text\") + \"\\n\"\n",
    "        \n",
    "        if not extracted_text.strip():  # If no text is found, use OCR\n",
    "            images = convert_from_path(file_path)\n",
    "            extracted_text = \"\\n\".join([self.ocr_processor(img) for img in images])\n",
    "        \n",
    "        return extracted_text.strip()\n",
    "    \n",
    "    def _format_text(self, text: str) -> str:\n",
    "        \"\"\"Cleans and formats extracted text for further processing.\"\"\"\n",
    "        text = re.sub(r'[^\\w\\s.,]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def _generate_context(self, text: str) -> str:\n",
    "        \"\"\"Generates structured context from formatted medical text.\"\"\"\n",
    "        return f\"Medical Report Analysis:\\n{text}\\nEnd of Report.\"\n",
    "    \n",
    "    def _extract_key_insights(self, context: str) -> Dict:\n",
    "        \"\"\"Extracts key insights including lab results, predicted diseases, and abnormalities.\"\"\"\n",
    "        lab_key_points = self._extract_lab_key_points(context)\n",
    "        predicted_disease = self._predict_disease(context)\n",
    "        abnormality_analysis = self._analyze_abnormalities(context)\n",
    "        \n",
    "        return {\n",
    "            \"lab_key_points\": lab_key_points,\n",
    "            \"predicted_disease\": predicted_disease,\n",
    "            \"abnormalities\": abnormality_analysis\n",
    "        }\n",
    "    \n",
    "    def _extract_lab_key_points(self, context: str) -> List[str]:\n",
    "        \"\"\"Extracts key points from the medical lab report using AI.\"\"\"\n",
    "        return self._medical_ai(context, task=\"extract_lab_values\")\n",
    "    \n",
    "    def _predict_disease(self, context: str) -> str:\n",
    "        \"\"\"Predicts potential diseases based on the provided medical context using AI.\"\"\"\n",
    "        return self._medical_ai(context, task=\"predict_disease\")\n",
    "    \n",
    "    def _analyze_abnormalities(self, context: str) -> str:\n",
    "        \"\"\"Analyzes the medical text for any abnormal indicators of sickness using AI.\"\"\"\n",
    "        return self._medical_ai(context, task=\"detect_abnormalities\")\n",
    "    \n",
    "    def _medical_ai(self, text: str, task: str) -> str:\n",
    "        \"\"\"Handles AI-based medical analysis dynamically to obscure implementation details.\"\"\"\n",
    "        if not self.ai_client:\n",
    "            return \"AI processing unavailable\"\n",
    "        response = self.ai_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI specialized in medical report analysis.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Task: {task}\\nText: {text}\"}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "# Usage Example:\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = MedicalScanPipeline()\n",
    "    report = pipeline.process_scan(\"sample_medical_report.pdf\")\n",
    "    print(json.dumps(report, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pytesseract\n",
    "import fitz  # PyMuPDF\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from typing import Dict, List\n",
    "import requests\n",
    "\n",
    "class MedicalScanPipeline:\n",
    "    \"\"\"\n",
    "    A high-performance, scalable pipeline for processing uploaded medical scan reports.\n",
    "    It extracts textual data, formats the content, generates context, and predicts key medical insights.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, disease_model: str = \"bert-base-uncased\", abnormality_model: str = \"distilbert-base-uncased\"):\n",
    "        self.ocr_processor = pytesseract.image_to_string\n",
    "        self.disease_pipeline = self._load_model_pipeline(disease_model)\n",
    "        self.abnormality_pipeline = self._load_model_pipeline(abnormality_model)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_model_pipeline(model_name: str):\n",
    "        \"\"\"Loads a transformer model for classification tasks.\"\"\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        return pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "    \n",
    "    def process_scan(self, file_path: str) -> Dict:\n",
    "        \"\"\"Processes a scanned medical document (PDF or image) and returns structured medical insights.\"\"\"\n",
    "        extracted_text = self._extract_text(file_path)\n",
    "        formatted_text = self._format_text(extracted_text)\n",
    "        context = self._generate_context(formatted_text)\n",
    "        key_insights = self._extract_key_insights(context)\n",
    "        return key_insights\n",
    "    \n",
    "    def _extract_text(self, file_path: str) -> str:\n",
    "        \"\"\"Extracts raw text from an uploaded scanned medical document (PDF or image).\"\"\"\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File {file_path} not found.\")\n",
    "        \n",
    "        text = \"\"\n",
    "        if file_path.lower().endswith(\".pdf\"):\n",
    "            text = self._extract_text_from_pdf(file_path)\n",
    "        else:\n",
    "            text = self.ocr_processor(Image.open(file_path))\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def _extract_text_from_pdf(self, file_path: str) -> str:\n",
    "        \"\"\"Extracts text from a PDF using PyMuPDF, with a fallback to OCR if necessary.\"\"\"\n",
    "        extracted_text = \"\"\n",
    "        with fitz.open(file_path) as doc:\n",
    "            for page in doc:\n",
    "                extracted_text += page.get_text(\"text\") + \"\\n\"\n",
    "        \n",
    "        if not extracted_text.strip():  # If no text is found, use OCR\n",
    "            images = convert_from_path(file_path)\n",
    "            extracted_text = \"\\n\".join([self.ocr_processor(img) for img in images])\n",
    "        \n",
    "        return extracted_text.strip()\n",
    "    \n",
    "    def _format_text(self, text: str) -> str:\n",
    "        \"\"\"Cleans and formats extracted text for further processing.\"\"\"\n",
    "        text = re.sub(r'[^\\w\\s.,]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def _generate_context(self, text: str) -> str:\n",
    "        \"\"\"Generates structured context from formatted medical text.\"\"\"\n",
    "        return f\"Medical Report Analysis:\\n{text}\\nEnd of Report.\"\n",
    "    \n",
    "    def _extract_key_insights(self, context: str) -> Dict:\n",
    "        \"\"\"Extracts key insights including lab results, predicted diseases, and abnormalities.\"\"\"\n",
    "        lab_key_points = self._extract_lab_key_points(context)\n",
    "        predicted_disease = self._predict_disease(context)\n",
    "        abnormality_analysis = self._analyze_abnormalities(context)\n",
    "        \n",
    "        return {\n",
    "            \"lab_key_points\": lab_key_points,\n",
    "            \"predicted_disease\": predicted_disease,\n",
    "            \"abnormalities\": abnormality_analysis\n",
    "        }\n",
    "    \n",
    "    def _extract_lab_key_points(self, context: str) -> List[str]:\n",
    "        \"\"\"Extracts key points from the medical lab report using AI.\"\"\"\n",
    "        return self._medical_ai(context, task=\"extract_lab_values\")\n",
    "    \n",
    "    def _predict_disease(self, context: str) -> str:\n",
    "        \"\"\"Predicts potential diseases based on the provided medical context using AI.\"\"\"\n",
    "        return self._medical_ai(context, task=\"predict_disease\")\n",
    "    \n",
    "    def _analyze_abnormalities(self, context: str) -> str:\n",
    "        \"\"\"Analyzes the medical text for any abnormal indicators of sickness using AI.\"\"\"\n",
    "        return self._medical_ai(context, task=\"detect_abnormalities\")\n",
    "    \n",
    "    def _medical_ai(self, text: str, task: str) -> str:\n",
    "        \"\"\"Handles AI-based medical analysis using a secure external API with cURL-like execution.\"\"\"\n",
    "        api_url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        data = {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI specialized in medical report analysis.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Task: {task}\\nText: {text}\"}\n",
    "            ]\n",
    "        }\n",
    "        response = requests.post(api_url, json=data, headers=headers)\n",
    "        return response.json().get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"AI processing unavailable\")\n",
    "\n",
    "# Usage Example:\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = MedicalScanPipeline()\n",
    "    report = pipeline.process_scan(\"sample_medical_report.pdf\")\n",
    "    print(json.dumps(report, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
