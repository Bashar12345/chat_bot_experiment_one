{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding models map text, sentences, or documents into a dense vector space, where similar texts have closer vector representations.\n",
    "```\n",
    "Use cases:\n",
    "Text similarity\n",
    "Document retrieval\n",
    "Semantic search\n",
    "Clustering\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vai/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-01-06 12:56:30.136141: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-06 12:56:30.335508: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736146590.410153   67281 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736146590.428997   67281 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-06 12:56:30.578067: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embedding Shape: (384,)\n",
      "First 5 Embedding Values: [-0.0285371  -0.06309644  0.02467403 -0.06235595  0.02788599]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load pre-trained SentenceTransformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for sample text\n",
    "text = \"LangChain is a framework for building AI applications with LLMs.\"\n",
    "embedding = model.encode(text)\n",
    "\n",
    "# Output vector shape\n",
    "print(f\"Text Embedding Shape: {embedding.shape}\")\n",
    "print(f\"First 5 Embedding Values: {embedding[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test Embeddings with Text Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Sample texts\n",
    "text1 = \"LangChain is great for building AI applications.\"\n",
    "text2 = \"OpenAI's GPT-3 is a powerful language model.\"\n",
    "\n",
    "# Generate embeddings\n",
    "embedding1 = model.encode(text1)\n",
    "embedding2 = model.encode(text2)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity = cosine_similarity([embedding1], [embedding2])\n",
    "print(f\"Cosine Similarity: {similarity[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Task: Build a Document Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(text1, text2, model):\n",
    "    embedding1 = model.encode(text1)\n",
    "    embedding2 = model.encode(text2)\n",
    "    similarity = cosine_similarity([embedding1], [embedding2])\n",
    "    return similarity[0][0]\n",
    "\n",
    "# Test similarity\n",
    "doc1 = \"LangChain provides tools for AI development.\"\n",
    "doc2 = \"AI tools like LangChain simplify complex tasks.\"\n",
    "print(f\"Document Similarity: {get_similarity(doc1, doc2, model)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Databases with ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "client = chromadb.Client(Settings())\n",
    "\n",
    "# Create a collection for storing embeddings\n",
    "collection = client.create_collection(name=\"docs\")\n",
    "\n",
    "print(\"ChromaDB setup complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents\n",
    "documents = [\n",
    "    \"LangChain is a framework for AI applications.\",\n",
    "    \"GPT-3 is a powerful language model from OpenAI.\",\n",
    "    \"ChromaDB is a vector database for storing embeddings.\"\n",
    "]\n",
    "ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "\n",
    "# Add documents to collection\n",
    "collection.add(documents=documents, ids=ids)\n",
    "print(\"Documents stored in ChromaDB!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Query collection for similar documents\n",
    "query_text = \"What is LangChain?\"\n",
    "results = collection.query(query_texts=[query_text], n_results=2)\n",
    "\n",
    "# Output results\n",
    "for doc_id, doc_text in zip(results[\"ids\"][0], results[\"documents\"][0]):\n",
    "    print(f\"Document ID: {doc_id}, Text: {doc_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Similarity with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for query\n",
    "query_embedding = model.encode(\"AI frameworks like LangChain\")\n",
    "\n",
    "# Add embeddings to collection (with metadata)\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    embeddings=[model.encode(doc) for doc in documents],\n",
    "    ids=ids\n",
    ")\n",
    "\n",
    "# Query collection using embeddings\n",
    "results = collection.query(query_embeddings=[query_embedding], n_results=2)\n",
    "for doc_id, doc_text in zip(results[\"ids\"][0], results[\"documents\"][0]):\n",
    "    print(f\"Document ID: {doc_id}, Text: {doc_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
