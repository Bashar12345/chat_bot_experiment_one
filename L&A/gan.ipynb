{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs\n",
    "GANs are a type of deep learning model used for generating data similar to a given dataset.\n",
    "\n",
    "Applications:\n",
    "\n",
    "Image Generation (e.g., creating realistic human faces).\n",
    "\n",
    "Data Augmentation for training AI models.\n",
    "\n",
    "Style Transfer (e.g., turning sketches into photos).\n",
    "\n",
    "Video and Music Generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Architecture\n",
    "GANs consist of two neural networks:\n",
    "\n",
    "Generator (G):\n",
    "Creates fake data to fool the discriminator.\n",
    "\n",
    "Discriminator (D):\n",
    "Classifies data as real or fake.\n",
    "\n",
    "They work in a game-like setting (adversarial process):\n",
    "\n",
    "The generator tries to trick the discriminator.\n",
    "\n",
    "The discriminator learns to catch fakes.\n",
    "\n",
    "Both improve over time.\n",
    "\n",
    "### Key Concepts in GANs\n",
    "\n",
    "Loss Functions:\n",
    "\n",
    "Discriminator: Minimize binary cross-entropy loss to distinguish real and fake.\n",
    "\n",
    "Generator: Maximize probability of generating realistic data.\n",
    "Mode Collapse:\n",
    "\n",
    "The generator might produce repetitive outputs.\n",
    "\n",
    "Solution: Use Wasserstein GAN (WGAN) or Progressive GANs.\n",
    "Evaluation Metrics:\n",
    "\n",
    "FID Score (FrÃ©chet Inception Distance): Measures similarity between generated and real data.\n",
    "Advanced Variants:\n",
    "\n",
    "DCGAN (Deep Convolutional GAN): Convolutional layers for images.\n",
    "\n",
    "CycleGAN: Style transfer without paired data.\n",
    "\n",
    "StyleGAN: High-quality image generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Task: Generate Handwritten Digits (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(input_dim=100)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        # Prepare real and fake data\n",
    "        real_images = batch[0].view(-1, 784)\n",
    "        real_labels = torch.ones(real_images.size(0), 1)\n",
    "        fake_labels = torch.zeros(real_images.size(0), 1)\n",
    "\n",
    "        # Train Discriminator\n",
    "        outputs = discriminator(real_images)\n",
    "        d_loss_real = loss_fn(outputs, real_labels)\n",
    "\n",
    "        noise = torch.randn(real_images.size(0), 100)\n",
    "        fake_images = generator(noise)\n",
    "        outputs = discriminator(fake_images.detach())\n",
    "        d_loss_fake = loss_fn(outputs, fake_labels)\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        optimizer_d.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Train Generator\n",
    "        outputs = discriminator(fake_images)\n",
    "        g_loss = loss_fn(outputs, real_labels)\n",
    "        optimizer_g.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate fake images\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(64, 100)\n",
    "    generated_images = generator(noise).view(-1, 1, 28, 28)\n",
    "\n",
    "# Plot images\n",
    "grid = torchvision.utils.make_grid(generated_images, nrow=8, normalize=True)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vai/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CarGANModel' from 'transformers' (/home/vai/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CarGANModel, CarGANTokenizer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the CarGAN model and tokenizer\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m CarGANModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcargan\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CarGANModel' from 'transformers' (/home/vai/Desktop/chat_bot_experiment_one/myenv/lib/python3.12/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import CarGANModel, CarGANTokenizer\n",
    "\n",
    "# Load the CarGAN model and tokenizer\n",
    "model = CarGANModel.from_pretrained(\"cargan\")\n",
    "tokenizer = CarGANTokenizer.from_pretrained(\"cargan\")\n",
    "\n",
    "# Define the text prompt\n",
    "prompt = \"A sleek, red sports car with a spoiler\"\n",
    "\n",
    "# Tokenize the prompt\n",
    "inputs = tokenizer.encode_plus(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate the image\n",
    "outputs = model.generate(inputs)\n",
    "\n",
    "# Save the image to a file\n",
    "image = outputs[0].permute(1, 2, 0).numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.savefig(\"car_image.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
