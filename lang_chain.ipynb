{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LnagCahain trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "def preprocess_dataset(file_path, relevant_columns):\n",
    "    \"\"\"\n",
    "    Preprocess the Quranic dataset by removing unnecessary columns.\n",
    "    Args:\n",
    "    - file_path: Path to the CSV file.\n",
    "    - relevant_columns: List of columns to retain.\n",
    "\n",
    "    Returns:\n",
    "    - Processed DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df[relevant_columns]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in loading or processing dataset: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if error occurs\n",
    "\n",
    "\n",
    "# Specify relevant columns\n",
    "relevant_columns = ['surah_name_roman', 'surah_name_en', 'ayah_no_surah', 'ayah_en']\n",
    "quran_df = preprocess_dataset(\"TheQuranDataset.csv\", relevant_columns)\n",
    "\n",
    "if quran_df.empty:\n",
    "    print(\"The dataset could not be loaded. Please check the file path and content.\")\n",
    "    exit()  # Exit if the dataset is not properly loaded\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Chunk the dataset for LLM processing\n",
    "def preprocess_and_chunk(df, chunk_size=4000):\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset to create formatted context chunks.\n",
    "    Args:\n",
    "    - df: Processed DataFrame.\n",
    "    - chunk_size: Maximum character size for each chunk.\n",
    "\n",
    "    Returns:\n",
    "    - List of context chunks (list of str).\n",
    "    \"\"\"\n",
    "    context_lines = [\n",
    "        f\"Ayah {row['ayah_no_surah']} of Surah {row['surah_name_roman']} ({row['surah_name_en']}): \"\n",
    "        f\"'{row['ayah_en']}'\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "    combined_context = \"\\n\".join(context_lines)\n",
    "\n",
    "    # Chunk the combined context\n",
    "    context_chunks = [\n",
    "        combined_context[i:i + chunk_size]\n",
    "        for i in range(0, len(combined_context), chunk_size)\n",
    "    ]\n",
    "    return context_chunks\n",
    "\n",
    "\n",
    "context_chunks = preprocess_and_chunk(quran_df)\n",
    "\n",
    "if not context_chunks:\n",
    "    print(\"No context chunks created. Please check the dataset or preprocessing logic.\")\n",
    "    exit()  # Exit if no chunks are created\n",
    "\n",
    "\n",
    "# Query definition\n",
    "query = \"Does the Quran mention dogs? Provide references and context.\"\n",
    "\n",
    "# Define a prompt template\n",
    "prompt_template = \"\"\"\n",
    "Use the following Quranic data to answer the query and provide references with context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Query: {question}\n",
    "\"\"\"\n",
    "\n",
    "# Create a LangChain PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template\n",
    ")\n",
    "\n",
    "# Initialize the Ollama LLM\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "# Create an LLMChain for structured execution\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Execute the query on each chunk\n",
    "def execute_query_on_chunks(context_chunks, query):\n",
    "    \"\"\"\n",
    "    Executes a query on context chunks using the LLM chain.\n",
    "    Args:\n",
    "    - context_chunks: List of text chunks.\n",
    "    - query: Query string.\n",
    "\n",
    "    Returns:\n",
    "    - Combined results from all chunks.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for chunk in context_chunks:\n",
    "        inputs = {\"context\": chunk, \"question\": query}\n",
    "        try:\n",
    "            result = llm_chain.run(inputs)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk: {e}\")\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "\n",
    "final_result = execute_query_on_chunks(context_chunks, query)\n",
    "\n",
    "# Print the final output\n",
    "print(\"\\nOutput:\")\n",
    "print(final_result)\n",
    "\n",
    "\n",
    "# Keyword search function\n",
    "def keyword_search(keywords, df):\n",
    "    \"\"\"\n",
    "    Searches for ayahs containing specific keywords in the Quranic dataset.\n",
    "    Args:\n",
    "    - keywords: List of keywords to search for.\n",
    "    - df: DataFrame containing Quranic data.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with matched ayahs and relevant details.\n",
    "    \"\"\"\n",
    "    matches = df[\n",
    "        df['ayah_en'].str.contains('|'.join(keywords), case=False, na=False)\n",
    "    ]\n",
    "    return matches\n",
    "\n",
    "\n",
    "# Keywords related to \"dogs\"\n",
    "keywords = [\"dog\", \"dogs\", \"dogs talk\", \"speak\"]\n",
    "matched_ayahs = keyword_search(keywords, quran_df)\n",
    "\n",
    "# Display the results in a clean table format\n",
    "if not matched_ayahs.empty:\n",
    "    print(\"\\nMatched Ayahs:\")\n",
    "    print(\n",
    "        matched_ayahs.to_markdown(index=False)  # Use Markdown for table-like display\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nNo matches found for the given keywords.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
