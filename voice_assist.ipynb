{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import threading\n",
    "import speech_recognition as sr\n",
    "import openai\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pygame\n",
    "import tempfile\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class VoiceAssistant:\n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"Initialize the voice assistant with required components.\"\"\"\n",
    "        # Set up logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "        # OpenAI setup\n",
    "        openai.api_key = api_key\n",
    "\n",
    "        # Initialize speech recognizer\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.is_speaking = threading.Event()\n",
    "        self.interrupted = threading.Event()\n",
    "        self.speech_lock = threading.Lock()\n",
    "\n",
    "        # Initialize pygame mixer for audio playback\n",
    "        pygame.mixer.init()\n",
    "\n",
    "    def speak_text(self, text: str):\n",
    "        \"\"\"Convert text to speech using OpenAI's TTS and play it.\"\"\"\n",
    "        self.logger.info(f\"Speaking: {text}\")\n",
    "        self.is_speaking.set()\n",
    "        self.interrupted.clear()\n",
    "\n",
    "        try:\n",
    "            # Create a temporary file to store the speech audio\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as temp_file:\n",
    "                # Generate speech using OpenAI's TTS\n",
    "                response = openai.audio.speech.create(\n",
    "                    model=\"tts-1\",\n",
    "                    voice=\"alloy\",  # Options: alloy, echo, fable, onyx, nova, shimmer\n",
    "                    input=text\n",
    "                )\n",
    "                \n",
    "                # Save the audio to the temporary file\n",
    "                response.stream_to_file(temp_file.name)\n",
    "                \n",
    "                # Play the audio\n",
    "                pygame.mixer.music.load(temp_file.name)\n",
    "                pygame.mixer.music.play()\n",
    "                \n",
    "                # Wait for the audio to finish playing\n",
    "                while pygame.mixer.music.get_busy() and not self.interrupted.is_set():\n",
    "                    pygame.time.Clock().tick(10)\n",
    "                \n",
    "                # Clean up\n",
    "                pygame.mixer.music.stop()\n",
    "                os.unlink(temp_file.name)\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in text-to-speech: {e}\")\n",
    "        finally:\n",
    "            self.is_speaking.clear()\n",
    "\n",
    "    def listen_for_speech(self) -> str:\n",
    "        \"\"\"Listen for and convert speech to text.\"\"\"\n",
    "        with sr.Microphone() as source:\n",
    "            self.logger.info(\"Listening for your question...\")\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "            try:\n",
    "                audio_data = self.recognizer.listen(source, timeout=10, phrase_time_limit=30)\n",
    "                text = self.recognizer.recognize_google(audio_data, language='en-US')\n",
    "                self.logger.info(f\"Recognized text: {text}\")\n",
    "                return text\n",
    "            except sr.WaitTimeoutError:\n",
    "                return \"No speech detected.\"\n",
    "            except sr.UnknownValueError:\n",
    "                return \"Could not understand the audio.\"\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error in speech recognition: {e}\")\n",
    "                return f\"Error during speech recognition: {str(e)}\"\n",
    "\n",
    "    def get_gpt_response(self, prompt: str) -> str:\n",
    "        \"\"\"Get response from GPT model.\"\"\"\n",
    "        try:\n",
    "            self.logger.info(f\"Sending prompt to GPT: {prompt}\")\n",
    "            response = openai.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides clear, concise answers.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=150\n",
    "            )\n",
    "            response_text = response.choices[0].message.content.strip()\n",
    "            self.logger.info(f\"Received GPT response: {response_text}\")\n",
    "            return response_text\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error getting GPT response: {e}\")\n",
    "            return \"I apologize, but I encountered an error processing your request.\"\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main loop for running the assistant.\"\"\"\n",
    "        self.logger.info(\"Starting voice assistant...\")\n",
    "        self.speak_text(\"Voice assistant is ready. You can start speaking.\")\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                # Listen for user input\n",
    "                user_input = self.listen_for_speech()\n",
    "\n",
    "                # Process valid input\n",
    "                if user_input.lower() in [\"exit\", \"quit\", \"goodbye\"]:\n",
    "                    self.speak_text(\"Goodbye!\")\n",
    "                    self.logger.info(\"Exiting assistant...\")\n",
    "                    break\n",
    "\n",
    "                if user_input and user_input not in [\"No speech detected.\", \"Could not understand the audio.\"]:\n",
    "                    self.logger.info(f\"Processing user input: {user_input}\")\n",
    "\n",
    "                    # Get GPT response\n",
    "                    response = self.get_gpt_response(user_input)\n",
    "                    self.logger.info(f\"Speaking response: {response}\")\n",
    "\n",
    "                    # Speak the response\n",
    "                    self.speak_text(response)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"Assistant terminated by user\")\n",
    "            self.speak_text(\"Shutting down\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting voice assistant...\n",
      "INFO:__main__:Speaking: Voice assistant is ready. You can start speaking.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "/tmp/ipykernel_38864/1543711622.py:37: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(temp_file.name)\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_route.c:878:(find_matching_chmap) Found no matching channel map\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_a52.c:1001:(_snd_pcm_a52_open) a52 is only for playback\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_route.c:878:(find_matching_chmap) Found no matching channel map\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_a52.c:1001:(_snd_pcm_a52_open) a52 is only for playback\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "INFO:__main__:Listening for your question...\n",
      "INFO:__main__:Recognized text: tell me about ramp\n",
      "INFO:__main__:Processing user input: tell me about ramp\n",
      "INFO:__main__:Sending prompt to GPT: tell me about ramp\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Received GPT response: Ramp is a plant species with broad, flat leaves that is commonly found in North America and Europe. It is known for its strong, garlicky flavor and is often used in culinary dishes for its distinct taste. Ramps are also a good source of vitamins and minerals. They are harvested in the spring and are popular among foragers and chefs for their unique flavor profile. However, it's important to harvest ramps sustainably, as over-harvesting can threaten the wild populations.\n",
      "INFO:__main__:Speaking response: Ramp is a plant species with broad, flat leaves that is commonly found in North America and Europe. It is known for its strong, garlicky flavor and is often used in culinary dishes for its distinct taste. Ramps are also a good source of vitamins and minerals. They are harvested in the spring and are popular among foragers and chefs for their unique flavor profile. However, it's important to harvest ramps sustainably, as over-harvesting can threaten the wild populations.\n",
      "INFO:__main__:Speaking: Ramp is a plant species with broad, flat leaves that is commonly found in North America and Europe. It is known for its strong, garlicky flavor and is often used in culinary dishes for its distinct taste. Ramps are also a good source of vitamins and minerals. They are harvested in the spring and are popular among foragers and chefs for their unique flavor profile. However, it's important to harvest ramps sustainably, as over-harvesting can threaten the wild populations.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Assistant terminated by user\n",
      "INFO:__main__:Speaking: Shutting down\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "\n",
    "    # Fetch the OpenAI API key from the environment\n",
    "    api_key = os.getenv(\"OPEN_AI_API_KEY_VOICE\")\n",
    "\n",
    "    # Check if the API key is present\n",
    "    if not api_key:\n",
    "        print(\"Error: OPENAI_API_KEY_VOICE not found in environment variables.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Initialize and run the assistant\n",
    "        assistant = VoiceAssistant(api_key)\n",
    "        assistant.run()\n",
    "    except Exception as e:\n",
    "        print(f\"Error running assistant: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
